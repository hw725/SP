"""PA ë©”ì¸ í”„ë¡œì„¸ì„œ - ë‹¨ìˆœí™”"""

import pandas as pd
from typing import List, Dict
from sentence_splitter import split_target_sentences_advanced, split_source_with_spacy

def get_embedder_function(embedder_name: str):
    """ì„ë² ë” í•¨ìˆ˜ ë¡œë“œ"""
    
    if embedder_name == 'bge':
        try:
            import sys
            sys.path.append('../sa')
            from sa_embedders.bge import compute_embeddings_with_cache
            return compute_embeddings_with_cache
        except ImportError:
            return fallback_embedder
            
    elif embedder_name == 'st':
        try:
            import sys
            sys.path.append('../sa')
            from sa_embedders.sentence_transformer import compute_embeddings_with_cache
            return compute_embeddings_with_cache
        except ImportError:
            return fallback_embedder
    
    return fallback_embedder

def fallback_embedder(texts: List[str]):
    """ëŒ€ì²´ ì„ë² ë” - TF-IDF"""
    import numpy as np
    from sklearn.feature_extraction.text import TfidfVectorizer
    
    if not texts:
        return np.array([]).reshape(0, 512)
    
    try:
        vectorizer = TfidfVectorizer(max_features=512, ngram_range=(1, 2))
        embeddings = vectorizer.fit_transform(texts).toarray()
        
        # L2 ì •ê·œí™”
        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
        embeddings = embeddings / (norms + 1e-8)
        
        return embeddings
    except Exception:
        return np.random.randn(len(texts), 512)

def simple_align_paragraphs(
    tgt_sentences: List[str], 
    src_chunks: List[str], 
    embed_func,
    similarity_threshold: float = 0.3
) -> List[Dict]:
    """ë‹¨ìˆœ ì •ë ¬"""
    
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    
    if not tgt_sentences or not src_chunks:
        return []
    
    # ì„ë² ë”© ìƒì„±
    tgt_embeddings = embed_func(tgt_sentences)
    src_embeddings = embed_func(src_chunks)
    
    # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
    sim_matrix = cosine_similarity(tgt_embeddings, src_embeddings)
    
    # ë‹¨ìˆœ ì •ë ¬
    alignments = []
    used_src_indices = set()
    
    for tgt_idx, tgt_sent in enumerate(tgt_sentences):
        similarities = sim_matrix[tgt_idx]
        
        best_score = -1.0
        best_src_idx = -1
        
        for src_idx in range(len(src_chunks)):
            if src_idx not in used_src_indices:
                if similarities[src_idx] > best_score:
                    best_score = similarities[src_idx]
                    best_src_idx = src_idx
        
        if best_src_idx != -1:
            used_src_indices.add(best_src_idx)
            src_text = src_chunks[best_src_idx]
        else:
            src_text = ""
        
        alignments.append({
            'ë¬¸ë‹¨ì‹ë³„ì': 1,
            'ì›ë¬¸': src_text,
            'ë²ˆì—­ë¬¸': tgt_sent,
            'similarity': best_score,
            'split_method': 'spacy_lg',
            'align_method': 'simple_align'
        })
    
    # ì‚¬ìš©ë˜ì§€ ì•Šì€ ì›ë¬¸ë“¤ ì¶”ê°€
    for src_idx, src_chunk in enumerate(src_chunks):
        if src_idx not in used_src_indices:
            alignments.append({
                'ë¬¸ë‹¨ì‹ë³„ì': 1,
                'ì›ë¬¸': src_chunk,
                'ë²ˆì—­ë¬¸': "",
                'similarity': 0.0,
                'split_method': 'spacy_lg',
                'align_method': 'unmatched_source'
            })
    
    return alignments

def process_paragraph_file(
    input_file: str, 
    output_file: str, 
    embedder_name: str = 'bge',
    max_length: int = 150,
    similarity_threshold: float = 0.3
):
    """íŒŒì¼ ë‹¨ìœ„ ì²˜ë¦¬ (ë©”ì¸ í•¨ìˆ˜)"""
    
    print(f"ğŸ“‚ PA íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {input_file}")
    
    try:
        # Excel íŒŒì¼ ë¡œë“œ
        df = pd.read_excel(input_file)
        print(f"ğŸ“„ {len(df)}ê°œ ë¬¸ë‹¨ ë¡œë“œë¨")
        
    except FileNotFoundError:
        print(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
        return None
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì—ëŸ¬: {e}")
        return None
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    if 'ì›ë¬¸' not in df.columns or 'ë²ˆì—­ë¬¸' not in df.columns:
        print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: 'ì›ë¬¸', 'ë²ˆì—­ë¬¸'")
        print(f"í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")
        return None
    
    # ì„ë² ë” ë¡œë“œ
    try:
        embed_func = get_embedder_function(embedder_name)
        print(f"ğŸ§  ì„ë² ë” ë¡œë“œ ì™„ë£Œ: {embedder_name}")
    except Exception as e:
        print(f"âŒ ì„ë² ë” ë¡œë“œ ì‹¤íŒ¨: {e}")
        embed_func = fallback_embedder
    
    all_results = []
    
    for idx, row in df.iterrows():
        src_paragraph = str(row.get('ì›ë¬¸', '')).strip()
        tgt_paragraph = str(row.get('ë²ˆì—­ë¬¸', '')).strip()
        
        if not src_paragraph or not tgt_paragraph:
            print(f"âš ï¸ ë¹ˆ ë‚´ìš© ê±´ë„ˆëœ€: í–‰ {idx + 1}")
            continue
        
        try:
            print(f"ğŸ“ ì²˜ë¦¬ ì¤‘: ë¬¸ë‹¨ {idx + 1}/{len(df)}")
            
            # âœ… ë¬¸ì¥ ë¶„í•  (ì˜¬ë°”ë¥¸ í˜¸ì¶œ)
            tgt_sentences = split_target_sentences_advanced(tgt_paragraph, max_length)
            src_chunks = split_source_with_spacy(src_paragraph, tgt_sentences)  # List[str] ì „ë‹¬
            
            print(f"   ë²ˆì—­ë¬¸: {len(tgt_sentences)}ê°œ ë¬¸ì¥")
            print(f"   ì›ë¬¸: {len(src_chunks)}ê°œ ì²­í¬")
            
            # ì •ë ¬ ìˆ˜í–‰
            alignments = simple_align_paragraphs(
                tgt_sentences, 
                src_chunks, 
                embed_func, 
                similarity_threshold
            )
            
            # ë¬¸ë‹¨ì‹ë³„ì ì—…ë°ì´íŠ¸
            for result in alignments:
                result['ë¬¸ë‹¨ì‹ë³„ì'] = idx + 1
            
            all_results.extend(alignments)
            
        except Exception as e:
            print(f"âŒ ë¬¸ë‹¨ {idx + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()  # ë””ë²„ê¹…ìš© ìƒì„¸ ì—ëŸ¬
            continue
    
    if not all_results:
        print("âŒ ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ê²°ê³¼ ì €ì¥
    try:
        result_df = pd.DataFrame(all_results)
        
        # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
        available_columns = result_df.columns.tolist()
        desired_columns = ['ë¬¸ë‹¨ì‹ë³„ì', 'ì›ë¬¸', 'ë²ˆì—­ë¬¸', 'similarity', 'split_method', 'align_method']
        final_columns = [col for col in desired_columns if col in available_columns]
        
        result_df = result_df[final_columns]
        result_df.to_excel(output_file, index=False)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        print(f"ğŸ“Š ì´ {len(all_results)}ê°œ ë¬¸ì¥ ìŒ ìƒì„±")
        
        return result_df
        
    except Exception as e:
        print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None