"""PA ì „ìš© ì •ë ¬ê¸° - SA DP ë°©ì‹ ì ìš© (ìµœì¢…)"""

import sys
import os
sys.path.append('../sa')
import pandas as pd
from typing import List, Dict

from sentence_splitter import split_target_sentences_advanced, split_source_with_spacy

# âœ… SA ì„ë² ë” ì§ì ‘ import
def get_embedder_function(embedder_name: str):
    """SA ì„ë² ë” í•¨ìˆ˜ ì§ì ‘ ë¡œë“œ"""
    
    if embedder_name == 'bge':
        try:
            from sa_embedders.bge import compute_embeddings_with_cache
            return compute_embeddings_with_cache
        except ImportError:
            print("âŒ BGE ì„ë² ë” import ì‹¤íŒ¨")
            return fallback_embedder
            
    elif embedder_name == 'st':
        try:
            from sa_embedders.sentence_transformer import compute_embeddings_with_cache
            return compute_embeddings_with_cache
        except ImportError:
            print("âŒ SentenceTransformer ì„ë² ë” import ì‹¤íŒ¨")
            return fallback_embedder
            
    elif embedder_name == 'openai':
        try:
            from sa_embedders.openai import compute_embeddings_with_cache
            return compute_embeddings_with_cache
        except ImportError:
            print("âŒ OpenAI ì„ë² ë” import ì‹¤íŒ¨")
            return fallback_embedder
    
    return fallback_embedder

def fallback_embedder(texts: List[str]):
    """ëŒ€ì²´ ì„ë² ë” - TF-IDF ê¸°ë°˜"""
    
    import numpy as np
    from sklearn.feature_extraction.text import TfidfVectorizer
    
    if not texts:
        return np.array([]).reshape(0, 512)
    
    try:
        vectorizer = TfidfVectorizer(max_features=512, ngram_range=(1, 2))
        embeddings = vectorizer.fit_transform(texts).toarray()
        
        # L2 ì •ê·œí™”
        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
        embeddings = embeddings / (norms + 1e-8)
        
        return embeddings
    except Exception as e:
        print(f"âš ï¸ TF-IDF ì„ë² ë” ì‹¤íŒ¨: {e}")
        return np.random.randn(len(texts), 512)

def align_paragraphs_with_sa_dp(
    tgt_sentences: List[str], 
    src_chunks: List[str], 
    embed_func,
    similarity_threshold: float = 0.3
) -> List[Dict]:
    """SA DP ë¡œì§ì„ PA ë°©í–¥ìœ¼ë¡œ ì ìš© (ìµœì¢…)"""
    
    if not tgt_sentences or not src_chunks:
        return []
    
    print(f"ğŸ¯ PA ì •ë ¬ ì‹œì‘ (SA DP): {len(tgt_sentences)}ê°œ ë²ˆì—­ë¬¸ â†’ {len(src_chunks)}ê°œ ì›ë¬¸")
    
    try:
        # âœ… SA í•¨ìˆ˜ ì§ì ‘ import (í™•ì¸ëœ í•¨ìˆ˜ëª…)
        import importlib.util
        sa_path = os.path.abspath(os.path.join('..', 'sa'))
        aligner_path = os.path.join(sa_path, 'aligner.py')
        
        spec = importlib.util.spec_from_file_location("sa_aligner_module", aligner_path)
        sa_aligner = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(sa_aligner)
        
        # âœ… í™•ì¸ëœ í•¨ìˆ˜ ì‚¬ìš©
        sa_align_func = sa_aligner.align_tokens_with_embeddings
        
        print("ğŸ”— SA DP í•¨ìˆ˜ ì—°ë™ ì„±ê³µ: align_tokens_with_embeddings")
        
        # âœ… ì •í™•í•œ ë§¤ê°œë³€ìˆ˜ë¡œ í˜¸ì¶œ
        sa_alignments = sa_align_func(
            src_units=tgt_sentences,          # PA: ë²ˆì—­ë¬¸ì´ ê¸°ì¤€ (src_units)
            tgt_units=src_chunks,             # PA: ì›ë¬¸ì´ ì •ë ¬ ëŒ€ìƒ (tgt_units)
            embed_func=embed_func,
            similarity_threshold=similarity_threshold
        )
        
        print(f"ğŸ“Š SA DP ê²°ê³¼: {len(sa_alignments) if sa_alignments else 0}ê°œ ì •ë ¬")
        
        # âœ… ê²°ê³¼ ë³€í™˜ (SA â†’ PA í˜•ì‹)
        pa_alignments = []
        
        if sa_alignments:
            for align in sa_alignments:
                # SA ê²°ê³¼ í˜•ì‹ì— ë”°ë¥¸ ì²˜ë¦¬
                if isinstance(align, dict):
                    # ë”•ì…”ë„ˆë¦¬ í˜•ì‹
                    src_text = align.get('src', '')      # SAì˜ src = PAì˜ ë²ˆì—­ë¬¸
                    tgt_text = align.get('tgt', '')      # SAì˜ tgt = PAì˜ ì›ë¬¸
                    score = align.get('score', 0.0)
                elif isinstance(align, (list, tuple)) and len(align) >= 2:
                    # ë¦¬ìŠ¤íŠ¸/íŠœí”Œ í˜•ì‹
                    src_text = str(align[0])  # SA src â†’ PA ë²ˆì—­ë¬¸
                    tgt_text = str(align[1])  # SA tgt â†’ PA ì›ë¬¸
                    score = float(align[2]) if len(align) > 2 else 0.0
                else:
                    print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” SA ê²°ê³¼ í˜•ì‹: {type(align)}")
                    continue
                
                pa_alignments.append({
                    'ë¬¸ë‹¨ì‹ë³„ì': 1,
                    'ì›ë¬¸': tgt_text,        # PA ì›ë¬¸ = SA tgt
                    'ë²ˆì—­ë¬¸': src_text,      # PA ë²ˆì—­ë¬¸ = SA src
                    'similarity': score,
                    'split_method': 'spacy_lg',
                    'align_method': 'sa_dp_align_tokens_with_embeddings'
                })
        
        if pa_alignments:
            print(f"âœ… SA DP ì •ë ¬ ì„±ê³µ: {len(pa_alignments)}ê°œ í•­ëª©")
            return pa_alignments
        else:
            print("âš ï¸ SAì—ì„œ ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            
    except Exception as e:
        print(f"âš ï¸ SA DP ì—°ë™ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    
    # SA ì—°ë™ ì‹¤íŒ¨ì‹œ ê³ í’ˆì§ˆ ëŒ€ì²´ ì •ë ¬
    print("ğŸ”„ ê³ í’ˆì§ˆ ëŒ€ì²´ ì •ë ¬ ë°©ì‹ ì‚¬ìš©...")
    return advanced_align_paragraphs(tgt_sentences, src_chunks, embed_func, similarity_threshold)

def advanced_align_paragraphs(
    tgt_sentences: List[str], 
    src_chunks: List[str], 
    embed_func,
    similarity_threshold: float = 0.3
) -> List[Dict]:
    """ê³ í’ˆì§ˆ ëŒ€ì²´ ì •ë ¬ (DP ìŠ¤íƒ€ì¼)"""
    
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    
    # ì„ë² ë”© ìƒì„±
    tgt_embeddings = embed_func(tgt_sentences)
    src_embeddings = embed_func(src_chunks)
    
    # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
    sim_matrix = cosine_similarity(tgt_embeddings, src_embeddings)
    
    # âœ… DP ìŠ¤íƒ€ì¼ ì •ë ¬ (ìˆœì„œ ë³´ì¡´ + ë¬´ê²°ì„± ë³´ì¥)
    alignments = []
    used_src_indices = set()
    
    # ë²ˆì—­ë¬¸ ìˆœì„œ ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬
    for tgt_idx, tgt_sent in enumerate(tgt_sentences):
        # ê° ë²ˆì—­ë¬¸ì— ëŒ€í•´ ì‚¬ìš©ë˜ì§€ ì•Šì€ ì›ë¬¸ ì¤‘ ìµœì  ë§¤ì¹­
        similarities = sim_matrix[tgt_idx]
        
        best_score = -1.0
        best_src_idx = -1
        
        for src_idx in range(len(src_chunks)):
            if src_idx not in used_src_indices:
                if similarities[src_idx] > best_score:
                    best_score = similarities[src_idx]
                    best_src_idx = src_idx
        
        if best_src_idx != -1:
            used_src_indices.add(best_src_idx)
            src_text = src_chunks[best_src_idx]
        else:
            src_text = ""
        
        alignments.append({
            'ë¬¸ë‹¨ì‹ë³„ì': 1,
            'ì›ë¬¸': src_text,
            'ë²ˆì—­ë¬¸': tgt_sent,
            'similarity': best_score,
            'split_method': 'spacy_lg',
            'align_method': 'advanced_dp_style'
        })
    
    # ì‚¬ìš©ë˜ì§€ ì•Šì€ ì›ë¬¸ë“¤ ì¶”ê°€ (ë¬´ê²°ì„± ë³´ì¥)
    for src_idx, src_chunk in enumerate(src_chunks):
        if src_idx not in used_src_indices:
            alignments.append({
                'ë¬¸ë‹¨ì‹ë³„ì': 1,
                'ì›ë¬¸': src_chunk,
                'ë²ˆì—­ë¬¸': "",
                'similarity': 0.0,
                'split_method': 'spacy_lg',
                'align_method': 'unmatched_source'
            })
    
    print(f"âœ… ê³ í’ˆì§ˆ ëŒ€ì²´ ì •ë ¬ ì™„ë£Œ: {len(alignments)}ê°œ í•­ëª©")
    return alignments

# ê¸°ì¡´ process í•¨ìˆ˜ë“¤ ìœ ì§€...
def process_paragraph_alignment(
    src_paragraph: str, 
    tgt_paragraph: str, 
    embedder_name: str = 'bge',
    max_length: int = 150,
    similarity_threshold: float = 0.3
):
    """PA ì²˜ë¦¬ (SA DP ì—°ë™)"""
    
    print(f"ğŸ”„ PA ì²˜ë¦¬ ì‹œì‘")
    
    # 1. ë¶„í• 
    tgt_sentences = split_target_sentences_advanced(tgt_paragraph, max_length)
    src_chunks = split_source_with_spacy(src_paragraph, len(tgt_sentences))
    
    print(f"   ë²ˆì—­ë¬¸: {len(tgt_sentences)}ê°œ ë¬¸ì¥")
    print(f"   ì›ë¬¸: {len(src_chunks)}ê°œ ì²­í¬")
    
    # 2. ì„ë² ë” ë¡œë“œ
    embed_func = get_embedder_function(embedder_name)
    
    # 3. SA DP ì •ë ¬
    alignments = align_paragraphs_with_sa_dp(
        tgt_sentences, 
        src_chunks, 
        embed_func, 
        similarity_threshold
    )
    
    return alignments

def process_paragraph_file(
    input_file: str, 
    output_file: str, 
    embedder_name: str = 'bge',
    max_length: int = 150,
    similarity_threshold: float = 0.3
):
    """íŒŒì¼ ë‹¨ìœ„ ì²˜ë¦¬ - ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ëª…"""
    
    print(f"ğŸ“‚ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {input_file}")
    
    # Excel íŒŒì¼ ë¡œë“œ
    df = pd.read_excel(input_file)
    
    all_results = []
    
    for idx, row in df.iterrows():
        src_paragraph = str(row.get('ì›ë¬¸', ''))      # âœ… ì…ë ¥ ì»¬ëŸ¼ëª…
        tgt_paragraph = str(row.get('ë²ˆì—­ë¬¸', ''))    # âœ… ì…ë ¥ ì»¬ëŸ¼ëª…
        
        if src_paragraph and tgt_paragraph:
            print(f"ğŸ“ ì²˜ë¦¬ ì¤‘: ë¬¸ë‹¨ {idx + 1}")
            
            results = process_paragraph_alignment(
                src_paragraph, 
                tgt_paragraph,
                embedder_name=embedder_name,
                max_length=max_length,
                similarity_threshold=similarity_threshold
            )
            
            # ë¬¸ë‹¨ì‹ë³„ì ì—…ë°ì´íŠ¸
            for result in results:
                result['ë¬¸ë‹¨ì‹ë³„ì'] = idx + 1
            
            all_results.extend(results)
    
    # ê²°ê³¼ ì €ì¥ (ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ëª…)
    result_df = pd.DataFrame(all_results)
    
    # âœ… ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
    final_columns = ['ë¬¸ë‹¨ì‹ë³„ì', 'ì›ë¬¸', 'ë²ˆì—­ë¬¸', 'similarity', 'split_method', 'align_method']
    result_df = result_df[final_columns]
    
    result_df.to_excel(output_file, index=False)
    
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
    print(f"ğŸ“Š ì´ {len(all_results)}ê°œ ë¬¸ì¥ ìŒ ìƒì„±")
    
    return result_df