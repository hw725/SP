"""í† í° ì •ë ¬ ëª¨ë“ˆ - regex ì§€ì›"""

import numpy as np
import re
import regex  # ðŸ†• ìœ ë‹ˆì½”ë“œ ì†ì„± ì •ê·œì‹
from typing import List, Dict, Tuple, Optional, Callable, Any
import logging
from sa_embedders import compute_embeddings_with_cache  # ðŸ”§ ìˆ˜ì •

logger = logging.getLogger(__name__)

def align_tokens_with_embeddings(
    src_units: List[str], 
    tgt_units: List[str], 
    embed_func: Callable = None,  # ðŸ”§ íŒŒë¼ë¯¸í„° ì¶”ê°€
    similarity_threshold: float = 0.5
) -> List[Dict[str, Any]]:
    """í† í° ì •ë ¬ í•¨ìˆ˜ - embed_func íŒŒë¼ë¯¸í„° ì§€ì›"""
    
    if not src_units or not tgt_units:
        return []
    
    # embed_funcê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ìž„ë² ë” ì‚¬ìš©
    if embed_func is None:
        from sa_embedders import compute_embeddings_with_cache
        embed_func = compute_embeddings_with_cache
    
    try:
        # ìž„ë² ë”© ìƒì„±
        src_embeddings = embed_func(src_units)
        tgt_embeddings = embed_func(tgt_units)
        
        alignments = []
        
        # ê° ì›ë¬¸ ë‹¨ìœ„ì— ëŒ€í•´ ìµœê³  ë§¤ì¹­ ì°¾ê¸°
        for i, src_unit in enumerate(src_units):
            src_emb = src_embeddings[i]
            
            best_score = -1.0
            best_tgt_idx = -1
            
            for j, tgt_unit in enumerate(tgt_units):
                tgt_emb = tgt_embeddings[j]
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = np.dot(src_emb, tgt_emb) / (
                    np.linalg.norm(src_emb) * np.linalg.norm(tgt_emb) + 1e-8
                )
                
                if similarity > best_score and similarity >= similarity_threshold:
                    best_score = similarity
                    best_tgt_idx = j
            
            # ì •ë ¬ ê²°ê³¼ ì¶”ê°€
            if best_tgt_idx != -1:
                alignment = {
                    'src_idx': i,
                    'tgt_idx': best_tgt_idx,
                    'src': src_unit,
                    'tgt': tgt_units[best_tgt_idx],
                    'score': float(best_score)
                }
                alignments.append(alignment)
        
        logger.info(f"âœ… ì •ë ¬ ì™„ë£Œ: {len(src_units)} â†’ {len(tgt_units)} ({len(alignments)}ê°œ ì •ë ¬)")
        return alignments
        
    except Exception as e:
        logger.error(f"âŒ ì •ë ¬ ì‹¤íŒ¨: {e}")
        return []

def _calculate_enhanced_confidence(src_text: str, tgt_text: str, similarity_matrix: np.ndarray) -> float:
    """ê°•í™”ëœ ì‹ ë¢°ë„ ê³„ì‚°"""
    
    base_confidence = np.max(similarity_matrix) if similarity_matrix.size > 0 else 0.3
    
    # í•œìž ë§¤ì¹­ ë³´ë„ˆìŠ¤
    han_bonus = _calculate_han_matching_bonus(src_text, tgt_text)
    
    # ê¸¸ì´ ë¹„ìœ¨ ë³´ë„ˆìŠ¤
    len_ratio = min(len(src_text), len(tgt_text)) / max(len(src_text), len(tgt_text)) if max(len(src_text), len(tgt_text)) > 0 else 0
    length_bonus = len_ratio * 0.1
    
    return min(1.0, base_confidence + han_bonus + length_bonus)

def _calculate_han_matching_bonus(src_text: str, tgt_text: str) -> float:
    """ðŸ†• í•œìž ë§¤ì¹­ ë³´ë„ˆìŠ¤ ê³„ì‚°"""
    
    try:
        # ì›ë¬¸ì—ì„œ í•œìž ì¶”ì¶œ
        src_han = set(regex.findall(r'\p{Han}', src_text))
        # ë²ˆì—­ë¬¸ì—ì„œ í•œìž ì¶”ì¶œ 
        tgt_han = set(regex.findall(r'\p{Han}', tgt_text))
        
        if not src_han:
            return 0.0
        
        # í•œìž ì¼ì¹˜ìœ¨ ê³„ì‚°
        common_han = src_han & tgt_han
        if common_han:
            match_ratio = len(common_han) / len(src_han)
            return match_ratio * 0.3  # ìµœëŒ€ 0.3 ë³´ë„ˆìŠ¤
        
        return 0.0
        
    except Exception as e:
        logger.debug(f"í•œìž ë§¤ì¹­ ë³´ë„ˆìŠ¤ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0

def _fallback_alignment(src_units: List[str], tgt_units: List[str]) -> List[Dict]:
    """ë°±ì—… ì •ë ¬"""
    
    alignments = []
    min_len = min(len(src_units), len(tgt_units))
    
    for i in range(min_len):
        # ðŸ†• ë°±ì—…ì—ì„œë„ í•œìž ë§¤ì¹­ ì‹œë„
        han_bonus = _calculate_han_matching_bonus(src_units[i], tgt_units[i])
        confidence = 0.3 + han_bonus
        
        alignments.append({
            'src_idx': i,
            'tgt_idx': i,
            'src_text': src_units[i],
            'tgt_text': tgt_units[i],
            'confidence': float(confidence),
            'alignment_type': '1:1-fallback'
        })
    
    return alignments

# ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ wrapper
def align_tokens(src_units: List[str], tgt_units: List[str], embed_func: Callable = None) -> List[Dict[str, Any]]:
    """processor.py í˜¸í™˜ìš© wrapper"""
    return align_tokens_with_embeddings(src_units, tgt_units, embed_func=embed_func)