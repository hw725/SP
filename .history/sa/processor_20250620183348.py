"""ë¬¸ì¥ ë‹¨ìœ„ ì²˜ë¦¬ ë° ì •ë ¬ ëª¨ë“ˆ - ì§„í–‰ë¥  í‘œì‹œ í¬í•¨"""

import logging
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from tqdm import tqdm  # ì§„í–‰ë¥  í‘œì‹œ ì¶”ê°€
from io_utils import load_excel_file as load_excel, save_alignment_results as save_excel
from sa_tokenizers import split_src_meaning_units, split_tgt_meaning_units
from sa_embedders import compute_embeddings_with_cache
from aligner import align_tokens_with_embeddings as align_tokens

# punctuation import ì•ˆì „ ì²˜ë¦¬
try:
    from punctuation import process_punctuation
except ImportError:
    def process_punctuation(alignments, src_units, tgt_units):
        return alignments

logger = logging.getLogger(__name__)

def process_sentence(
    src_text: str,
    tgt_text: str,
    use_semantic: bool = True,
    min_tokens: int = 1,
    max_tokens: int = 10,
    **kwargs
) -> Dict[str, Any]:
    """ë‹¨ì¼ ë¬¸ì¥ ì²˜ë¦¬"""
    
    try:
        # 1. í† í¬ë‚˜ì´ì§•
        src_units = split_src_meaning_units(
            src_text, 
            min_tokens=min_tokens, 
            max_tokens=max_tokens,
            use_advanced=True
        )
        
        tgt_units = split_tgt_meaning_units(
            src_text,
            tgt_text,
            use_semantic=use_semantic,
            min_tokens=min_tokens,
            max_tokens=max_tokens,
            embed_func=compute_embeddings_with_cache if use_semantic else None
        )
        
        # 2. ì •ë ¬
        alignments = align_tokens(
            src_units, 
            tgt_units,
            embed_func=compute_embeddings_with_cache
        )
        
        # 3. ê´„í˜¸ ì²˜ë¦¬
        processed_alignments = process_punctuation(alignments, src_units, tgt_units)
        
        return {
            'src_units': src_units,
            'tgt_units': tgt_units,
            'alignments': processed_alignments,
            'status': 'success'
        }
        
    except Exception as e:
        logger.error(f"âŒ ë¬¸ì¥ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return {
            'src_units': [],
            'tgt_units': [],
            'alignments': [],
            'status': 'failed',
            'error': str(e)
        }

def process_file(
    input_file: str,
    use_semantic: bool = True,
    min_tokens: int = 1,
    max_tokens: int = 10,
    save_results: bool = True,
    output_file: Optional[str] = None,
    **kwargs
) -> Optional[pd.DataFrame]:
    """íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ - ì§„í–‰ë¥  í‘œì‹œ í¬í•¨"""
    
    logger.info(f"ğŸ“ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {input_file}")
    
    try:
        # íŒŒì¼ ë¡œë“œ
        df = load_excel(input_file)
        if df is None:
            logger.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {input_file}")
            return None
        
        total_sentences = len(df)
        logger.info(f"ğŸ“Š ì²˜ë¦¬í•  ë¬¸ì¥ ìˆ˜: {total_sentences}")
        
        results = []
        
        # ğŸ¯ ë©”ì¸ ì§„í–‰ë¥  ë°” ì¶”ê°€
        progress_bar = tqdm(
            df.iterrows(), 
            total=total_sentences,
            desc="ğŸ”¤ ë¬¸ì¥ ì²˜ë¦¬",
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]",
            ncols=100
        )
        
        for idx, row in progress_bar:
            # ì§„í–‰ë¥  ë°” ì„¤ëª… ì—…ë°ì´íŠ¸
            progress_bar.set_description(f"ğŸ”¤ ë¬¸ì¥ {idx+1}/{total_sentences}")
            
            try:
                src_text = row.get('src', '')
                tgt_text = row.get('tgt', '')
                
                if not src_text or not tgt_text:
                    logger.warning(f"âš ï¸ ë¬¸ì¥ {idx+1}: ë¹ˆ í…ìŠ¤íŠ¸ - ê±´ë„ˆëœ€")
                    continue
                
                # 1. ì›ë¬¸ í† í¬ë‚˜ì´ì§•
                progress_bar.set_postfix_str("ì›ë¬¸ í† í¬ë‚˜ì´ì§•...")
                src_units = split_src_meaning_units(
                    src_text, 
                    min_tokens=min_tokens, 
                    max_tokens=max_tokens
                )
                
                # 2. ë²ˆì—­ë¬¸ í† í¬ë‚˜ì´ì§•  
                progress_bar.set_postfix_str("ë²ˆì—­ë¬¸ í† í¬ë‚˜ì´ì§•...")
                tgt_units = split_tgt_meaning_units(
                    src_text,
                    tgt_text,
                    use_semantic=use_semantic,
                    min_tokens=min_tokens,
                    max_tokens=max_tokens,
                    embed_func=compute_embeddings_with_cache if use_semantic else None
                )
                
                # 3. ì •ë ¬
                progress_bar.set_postfix_str("í† í° ì •ë ¬...")
                alignments = align_tokens(
                    src_units, 
                    tgt_units,
                    embed_func=compute_embeddings_with_cache
                )
                
                # 4. ê´„í˜¸ ì²˜ë¦¬
                progress_bar.set_postfix_str("ê´„í˜¸ ì²˜ë¦¬...")
                alignments = process_punctuation(alignments, src_units, tgt_units)
                
                # ê²°ê³¼ ì €ì¥
                row_result = {
                    'id': row.get('id', idx+1),
                    'src': src_text,
                    'tgt': tgt_text,
                    'src_units': src_units,
                    'tgt_units': tgt_units,
                    'alignments': alignments,
                    'src_count': len(src_units),
                    'tgt_count': len(tgt_units),
                    'alignment_count': len(alignments) if alignments else 0,
                    'status': 'success'
                }
                
                results.append(row_result)
                
                # ì„±ê³µ ë¡œê·¸ (ì¡°ìš©íˆ)
                if (idx + 1) % 10 == 0:  # 10ê°œë§ˆë‹¤ ë¡œê·¸
                    logger.info(f"âœ… {idx+1}/{total_sentences} ë¬¸ì¥ ì²˜ë¦¬ ì™„ë£Œ")
                
                # ì§„í–‰ë¥  ë°” ìƒíƒœ ì—…ë°ì´íŠ¸
                success_count = len(results)
                progress_bar.set_postfix_str(f"ì„±ê³µ: {success_count}")
                
            except Exception as e:
                logger.error(f"âŒ ë¬¸ì¥ {idx+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                
                # ì‹¤íŒ¨í•œ ê²½ìš°ë„ ê²°ê³¼ì— ì¶”ê°€
                row_result = {
                    'id': row.get('id', idx+1),
                    'src': row.get('src', ''),
                    'tgt': row.get('tgt', ''),
                    'src_units': [],
                    'tgt_units': [],
                    'alignments': [],
                    'src_count': 0,
                    'tgt_count': 0,
                    'alignment_count': 0,
                    'status': f'failed: {str(e)[:50]}'
                }
                results.append(row_result)
                
                progress_bar.set_postfix_str(f"ì‹¤íŒ¨: {str(e)[:20]}...")
        
        # ì§„í–‰ë¥  ë°” ì™„ë£Œ
        progress_bar.close()
        
        if not results:
            logger.error("âŒ ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # DataFrame ìƒì„±
        results_df = pd.DataFrame(results)
        
        # ê²°ê³¼ ì €ì¥
        if save_results:
            if output_file is None:
                output_file = input_file.replace('.xlsx', '_results.xlsx')
            
            print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘: {output_file}")
            if save_excel(results_df, output_file):
                logger.info(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
            else:
                logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {output_file}")
        
        # ìµœì¢… í†µê³„
        success_count = len(results_df[results_df['status'] == 'success'])
        total_processed = len(results_df)
        
        print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½:")
        print(f"   ğŸ“Š ì „ì²´ ë¬¸ì¥: {total_sentences}")
        print(f"   âœ… ì„±ê³µ: {success_count}")
        print(f"   âŒ ì‹¤íŒ¨: {total_processed - success_count}")
        print(f"   ğŸ“ˆ ì„±ê³µë¥ : {success_count/total_processed*100:.1f}%")
        
        return results_df
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None

def process_file_with_modules(
    input_file: str,
    output_file: str,
    tokenizer_module,
    embedder_module,
    use_semantic: bool = True,
    min_tokens: int = 1,
    max_tokens: int = 10,
    **kwargs
):
    """ëª¨ë“ˆì„ ë™ì ìœ¼ë¡œ ë°›ì•„ì„œ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ - ì§„í–‰ë¥  í‘œì‹œ í¬í•¨"""
    
    logger.info(f"ğŸ“ ë™ì  ëª¨ë“ˆë¡œ íŒŒì¼ ì²˜ë¦¬: {input_file}")
    
    try:
        # ë™ì  í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
        split_src = tokenizer_module.split_src_meaning_units
        split_tgt = tokenizer_module.split_tgt_meaning_units
        embed_func = embedder_module.compute_embeddings_with_cache
        
        from io_utils import load_excel_file, save_alignment_results
        
        df = load_excel_file(input_file)
        if df is None:
            return None
        
        total_sentences = len(df)
        logger.info(f"ğŸ“Š ì²˜ë¦¬í•  ë¬¸ì¥ ìˆ˜: {total_sentences}")
        
        results = []
        
        # ğŸ¯ ë©”ì¸ ì§„í–‰ë¥  ë°” ì¶”ê°€
        progress_bar = tqdm(
            df.iterrows(), 
            total=total_sentences,
            desc="ğŸ”¤ ë™ì  ëª¨ë“ˆ ì²˜ë¦¬",
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]",
            ncols=100
        )
        
        for idx, row in progress_bar:
            progress_bar.set_description(f"ğŸ”¤ ë¬¸ì¥ {idx+1}/{total_sentences}")
            
            try:
                src_text = row.get('src', '')
                tgt_text = row.get('tgt', '')
                
                if not src_text or not tgt_text:
                    continue
                
                # ë™ì  í† í¬ë‚˜ì´ì € ì‚¬ìš©
                progress_bar.set_postfix_str("í† í¬ë‚˜ì´ì§•...")
                src_units = split_src(src_text, min_tokens, max_tokens)
                tgt_units = split_tgt(
                    src_text, tgt_text, 
                    use_semantic=use_semantic,
                    embed_func=embed_func if use_semantic else None
                )
                
                # ë™ì  ì„ë² ë”ë¡œ ì •ë ¬
                progress_bar.set_postfix_str("ì •ë ¬...")
                from aligner import align_tokens
                alignments = align_tokens(src_units, tgt_units, embed_func=embed_func)
                
                results.append({
                    'id': row.get('id', idx+1),
                    'src': src_text, 'tgt': tgt_text,
                    'src_units': src_units, 'tgt_units': tgt_units,
                    'alignments': alignments,
                    'src_count': len(src_units), 'tgt_count': len(tgt_units),
                    'alignment_count': len(alignments), 'status': 'success'
                })
                
                progress_bar.set_postfix_str(f"ì„±ê³µ: {len(results)}")
                
            except Exception as e:
                logger.error(f"âŒ ë¬¸ì¥ {idx+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                progress_bar.set_postfix_str(f"ì‹¤íŒ¨: {str(e)[:20]}...")
        
        progress_bar.close()
        
        # ì €ì¥
        import pandas as pd
        results_df = pd.DataFrame(results)
        save_alignment_results(results_df, output_file)
        
        print(f"\nğŸ‰ ë™ì  ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ë¬¸ì¥")
        return results_df
        
    except Exception as e:
        logger.error(f"âŒ ë™ì  ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
    
    # í…ŒìŠ¤íŠ¸
    test_file = "test_data.xlsx"
    results = process_file(test_file)
    
    if results is not None:
        print("âœ… ì²˜ë¦¬ ì„±ê³µ")
        print(results.head())
    else:
        print("âŒ ì²˜ë¦¬ ì‹¤íŒ¨")
