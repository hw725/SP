"""ì‹¤ì œ ë°ì´í„°ì—ì„œ ì„ ë³„í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤"""

import pandas as pd
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_real_test_data():
    """ì²¨ë¶€ëœ ë°ì´í„°ì—ì„œ ì„ ë³„í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤"""
    
    # ë‹¤ì–‘í•œ ê¸¸ì´ì™€ íŒ¨í„´ì˜ ë¬¸ì¥ë“¤ì„ ì„ ë³„ (ì»¬ëŸ¼ëª…ì„ ì‹œìŠ¤í…œ í‘œì¤€ì— ë§ì¶¤)
    test_data = [
        # 1. ì§§ì€ í•œë¬¸ì¥ (ê¸°ë³¸ í…ŒìŠ¤íŠ¸)
        {
            "id": 14,
            "ì›ë¬¸": "èˆˆä¹Ÿë¼",
            "ë²ˆì—­ë¬¸": "èˆˆì´ë‹¤."
        },
        
        # 2. ì¤‘ê°„ ê¸¸ì´ (ì¡°ì‚¬/ì–´ë¯¸ í¬í•¨)
        {
            "id": 15,
            "ì›ë¬¸": "è’¹ì€ è–•(ë ´)ì´ìš” è‘­ëŠ” è˜†ä¹Ÿë¼",
            "ë²ˆì—­ë¬¸": "è’¹ì€ ë¬¼ì–µìƒˆì´ê³  è‘­ëŠ” ê°ˆëŒ€ì´ë‹¤."
        },
        
        # 3. ë³µí•©ë¬¸ (ì ‘ì†ì‚¬ í¬í•¨)
        {
            "id": 17,
            "ì›ë¬¸": "ç™½éœ²å‡æˆ¾çˆ²éœœç„¶å¾Œì— æ­²äº‹æˆì´ìš” åœ‹å®¶å¾…ç¦®ç„¶å¾Œèˆˆì´ë¼",
            "ë²ˆì—­ë¬¸": "ç™½éœ²ê°€ ì–¼ì–´ ì„œë¦¬ê°€ ëœ ë’¤ì—ì•¼ æ­²äº‹ê°€ ì´ë£¨ì–´ì§€ê³  åœ‹å®¶ëŠ” ç¦®ê°€ í–‰í•´ì§„ ë’¤ì—ì•¼ í¥ì„±í•œë‹¤."
        },
        
        # 4. ê¸´ ì„¤ëª…ë¬¸ (ë³µì¡í•œ êµ¬ì¡°)
        {
            "id": 18,
            "ì›ë¬¸": "ç®‹äº‘ è’¹è‘­åœ¨è¡†è‰ä¹‹ä¸­ì— è’¼è’¼ç„¶å½Šç››ì´ë¼ê°€ è‡³ç™½éœ²å‡æˆ¾çˆ²éœœì´ë©´ å‰‡æˆè€Œé»ƒì´ë¼",
            "ë²ˆì—­ë¬¸": "ç®‹äº‘ï¼š ê°ˆëŒ€ëŠ” ì—¬ëŸ¬ í’€ ê°€ìš´ë°ì— í‘¸ë¥´ê²Œ ë¬´ì„±í–ˆë‹¤ê°€ ç™½éœ²ê°€ ì–¼ì–´ ì„œë¦¬ê°€ ë˜ë©´ ë‹¤ ìë¼ ëˆ„ë˜ì§„ë‹¤."
        },
        
        # 5. ë¹„ìœ ë¬¸ (ì€ìœ ì  í‘œí˜„)
        {
            "id": 19,
            "ì›ë¬¸": "èˆˆè€…ëŠ” å–©è¡†æ°‘ä¹‹ä¸å¾è¥„å…¬æ”¿ä»¤è€…ëŠ” å¾—å‘¨ç¦®ä»¥æ•ä¹‹ë©´ å‰‡æœì´ë¼",
            "ë²ˆì—­ë¬¸": "èˆˆí•œ ê²ƒì€ è¥„å…¬ì˜ æ”¿ä»¤ì„ ë”°ë¥´ì§€ ì•ŠëŠ” ë°±ì„±ë“¤ì€ <êµ°ì£¼ê°€> å‘¨ç¦®ë¥¼ ë”°ë¼ êµí™”ì‹œí‚¤ë©´ ë³µì¢…í•œë‹¤ëŠ” ê²ƒì„ ë¹„ìœ í•œ ê²ƒì´ë‹¤."
        },
        
        # 6. ì‹œë¬¸ (ìš´ìœ¨ì´ ìˆëŠ” ì›ë¬¸)
        {
            "id": 13,
            "ì›ë¬¸": "è’¹è‘­è’¼è’¼ì´ëŸ¬ë‹ˆ ç™½éœ²çˆ²éœœì´ë¡œë‹¤",
            "ë²ˆì—­ë¬¸": "ê°ˆëŒ€ ë¬´ì„±í•˜ë”ë‹ˆ ç™½éœ² ì„œë¦¬ê°€ ë˜ì—ˆë„¤"
        },
        
        # 7. ì˜ë¬¸ë¬¸
        {
            "id": 20,
            "ì›ë¬¸": "æ‰€è¬‚ä¼Šäººì´ åœ¨æ°´ä¸€æ–¹ì´ì–¸ë§ˆëŠ”",
            "ë²ˆì—­ë¬¸": "ì´ë¥¸ë°” ê·¸ ë¶„ì´ ê°•ë¬¼ ì €ìª½ì— ìˆê±´ë§Œ"
        },
        
        # 8. ë§¤ìš° ê¸´ ë³µí•©ë¬¸ (ìµœê³  ë‚œì´ë„)
        {
            "id": 41,
            "ì›ë¬¸": "è‹¥é€†æµé¡æ´„è€Œå¾€å¾ä¹‹, å‰‡é“éšªé˜»ä¸”é•·é , ä¸å¯å¾—è‡³, è¨€é€†ç¦®ä»¥æ²»åœ‹, å‰‡ç„¡å¾—äººé“, çµ‚ä¸å¯è‡³. è‹¥é †æµé¡æ¸¸è€Œå¾€å¾ä¹‹, å‰‡å®›ç„¶åœ¨æ–¼æ°´ä¹‹ä¸­å¤®, è¨€é †ç¦®æ²»åœ‹, å‰‡å¾—äººä¹‹é“, è‡ªä¾†è¿å·±, æ­£è¿‘åœ¨ç¦®æ¨‚ä¹‹å…§.",
            "ë²ˆì—­ë¬¸": "ë§Œì¼ ë¬¼ì‚´ì„ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ì„œ ë”°ë¥¸ë‹¤ë©´ ê¸¸ì´ í—˜í•˜ê³  ë§‰íˆë©° ë©€ì–´ì„œ ë„ë‹¬í•  ìˆ˜ ì—†ë‹¤ëŠ” ê²ƒì€, ç¦®ì— ì–´ê¸‹ë‚˜ê²Œ ë‚˜ë¼ë¥¼ ë‹¤ìŠ¤ë¦¬ë©´ ì‚¬ëŒì„ ì–»ëŠ” ë°©ë„ê°€ ì—†ì–´ì„œ ëë‚´ ì´ë¥¼ ìˆ˜ ì—†ìŒì„ ë§í•œ ê²ƒì´ê³ , ë¬¼ì‚´ì— ìˆœì‘í•˜ë©° ë”°ë¼ ë‚´ë ¤ê°€ ë§Œë‚˜ë ¤ í•˜ë©´ å®›ç„¶íˆ ë¬¼ ê°€ìš´ë° ìˆë‹¤ëŠ” ê²ƒì€, ç¦®ì— ë”°ë¼ ë‚˜ë¼ë¥¼ ë‹¤ìŠ¤ë¦¬ë©´ ì‚¬ëŒì„ ì–»ëŠ” é“ì´ë‹ˆ ì ˆë¡œ ì™€ì„œ ë‚˜ë¥¼ ë§ì´í•¨ì´ ë°”ë¡œ ç¦®æ¨‚ì˜ ì•ˆì— ê°€ê¹Œì´ ìˆìŒì„ ë§í•œ ê²ƒì´ë‹¤."
        },
        
        # 9. ì¸ìš©ë¬¸ (ë”°ì˜´í‘œ í¬í•¨)
        {
            "id": 42,
            "ì›ë¬¸": "ç„¶å‰‡éç¦®, å¿…ä¸å¾—äºº, å¾—äºº, å¿…èƒ½å›ºåœ‹, å›ä½•ä»¥ä¸æ±‚ç”¨å‘¨ç¦®ä¹.",
            "ë²ˆì—­ë¬¸": "ê·¸ëŸ¬ë‹ˆ ç¦®ê°€ ì•„ë‹ˆë©´ ë°˜ë“œì‹œ ì‚¬ëŒì„ ì–»ì„ ìˆ˜ ì—†ê³ , ì‚¬ëŒì„ ì–»ì–´ì•¼ ë°˜ë“œì‹œ ë‚˜ë¼ë¥¼ ê²¬ê³ í•˜ê²Œ í•  ìˆ˜ ìˆëŠ”ë°, êµ°ì£¼ëŠ” ì–´ì°Œí•˜ì—¬ å‘¨ç¦® ë”°ë¦„ì„ ì¶”êµ¬í•˜ì§€ ì•ŠëŠ”ê°€."
        },
        
        # 10. ì „ë¬¸ ìš©ì–´ ì„¤ëª… (ì‚¬ì „ì‹ ì •ì˜)
        {
            "id": 52,
            "ì›ë¬¸": "æ­£ç¾©æ›°ï¼š'è’¹ è–• è‘­ è˜†', é‡‹è‰æ–‡, éƒ­ç’æ›°"è’¹, ä¼¼è‘è€Œç´°, é«˜æ•¸å°º.",
            "ë²ˆì—­ë¬¸": "æ­£ç¾©æ›°ï¼š'è’¹, è–•', 'è‘­, è˜†'ëŠ” â‰ªçˆ¾é›…â‰« <é‡‹è‰>ì˜ ê¸€ì¸ë° éƒ­ç’ì€ \"è’¹ì€ ë¬¼ì–µìƒˆ(è‘)ì™€ ë¹„ìŠ·í•œë° ê°€ëŠ˜ê³  í‚¤ê°€ æ•¸å°ºì´ë‹¤."
        }
    ]
    
    # ë°ì´í„° ê²€ì¦
    for i, row in enumerate(test_data):
        if not isinstance(row['id'], int):
            logger.warning(f"Row {i}: IDê°€ ì •ìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤: {row['id']}")
            row['id'] = int(row['id'])
        
        if not row['ì›ë¬¸'].strip():
            logger.error(f"Row {i}: ì›ë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
        if not row['ë²ˆì—­ë¬¸'].strip():
            logger.error(f"Row {i}: ë²ˆì—­ë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
    
    try:
        # DataFrame ìƒì„±
        df = pd.DataFrame(test_data)
        
        # ë°ì´í„° íƒ€ì… ëª…ì‹œì  ì„¤ì •
        df['id'] = df['id'].astype(int)
        df['ì›ë¬¸'] = df['ì›ë¬¸'].astype(str)
        df['ë²ˆì—­ë¬¸'] = df['ë²ˆì—­ë¬¸'].astype(str)
        
        # ì¤‘ë³µ ID í™•ì¸
        if df['id'].duplicated().any():
            logger.warning("ì¤‘ë³µëœ IDê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
            duplicates = df[df['id'].duplicated(keep=False)]['id'].unique()
            logger.warning(f"ì¤‘ë³µ ID: {duplicates}")
        
        # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
        output_path = Path("real_test_data.xlsx")
        df.to_excel(output_path, index=False, engine='openpyxl')
        
        logger.info(f"âœ… ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {output_path}")
        logger.info(f"ğŸ“Š ë¬¸ì¥ ìˆ˜: {len(test_data)}ê°œ")
        
        # ì•ˆì „í•œ ê¸¸ì´ë³„ í†µê³„ ê³„ì‚°
        src_lengths = [len(str(row['ì›ë¬¸'])) for row in test_data if row['ì›ë¬¸']]
        tgt_lengths = [len(str(row['ë²ˆì—­ë¬¸'])) for row in test_data if row['ë²ˆì—­ë¬¸']]
        
        if src_lengths and tgt_lengths:
            logger.info(f"ğŸ“ ê¸¸ì´ ë¶„í¬:")
            logger.info(f"   ì›ë¬¸ ê¸¸ì´: ìµœì†Œ {min(src_lengths)}, ìµœëŒ€ {max(src_lengths)}, í‰ê·  {sum(src_lengths)/len(src_lengths):.1f}")
            logger.info(f"   ë²ˆì—­ ê¸¸ì´: ìµœì†Œ {min(tgt_lengths)}, ìµœëŒ€ {max(tgt_lengths)}, í‰ê·  {sum(tgt_lengths)/len(tgt_lengths):.1f}")
            logger.info(f"   í‰ê·  í™•ì¥ ë¹„ìœ¨: {(sum(tgt_lengths)/sum(src_lengths)):.2f}")
        
        # ê¸¸ì´ë³„ ë¶„ë¥˜ ê°œì„ 
        length_categories = {
            'short': [i for i, length in enumerate(src_lengths) if length <= 10],
            'medium': [i for i, length in enumerate(src_lengths) if 10 < length <= 50],
            'long': [i for i, length in enumerate(src_lengths) if 50 < length <= 100],
            'very_long': [i for i, length in enumerate(src_lengths) if length > 100]
        }
        
        logger.info(f"\nğŸ“ ê¸¸ì´ë³„ ë¶„ë¥˜:")
        logger.info(f"   â€¢ ì§§ì€ ë¬¸ì¥ (â‰¤10ì): {len(length_categories['short'])}ê°œ")
        logger.info(f"   â€¢ ì¤‘ê°„ ë¬¸ì¥ (11-50ì): {len(length_categories['medium'])}ê°œ") 
        logger.info(f"   â€¢ ê¸´ ë¬¸ì¥ (51-100ì): {len(length_categories['long'])}ê°œ")
        logger.info(f"   â€¢ ë§¤ìš° ê¸´ ë¬¸ì¥ (>100ì): {len(length_categories['very_long'])}ê°œ")
        
        # íŠ¹ì§•ë³„ ë¶„ë¥˜ ê°œì„ 
        feature_analysis = analyze_text_features(test_data)
        logger.info(f"\nğŸ¯ íŠ¹ì§•ë³„ ë¶„ë¥˜:")
        for feature, count in feature_analysis.items():
            logger.info(f"   â€¢ {feature}: {count}ê°œ")
        
        # ë¯¸ë¦¬ë³´ê¸°
        logger.info(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
        for i, row in enumerate(test_data[:3], 1):
            src_preview = str(row['ì›ë¬¸'])[:50] + ('...' if len(str(row['ì›ë¬¸'])) > 50 else '')
            tgt_preview = str(row['ë²ˆì—­ë¬¸'])[:50] + ('...' if len(str(row['ë²ˆì—­ë¬¸'])) > 50 else '')
            logger.info(f"{i}. [ID {row['id']}] ì›ë¬¸: {src_preview}")
            logger.info(f"   ë²ˆì—­: {tgt_preview}\n")
        
        return output_path
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

def analyze_text_features(test_data):
    """í…ìŠ¤íŠ¸ íŠ¹ì§• ë¶„ì„"""
    features = {
        'í•œì+ì¡°ì‚¬ í˜¼í•©': 0,
        'ì‹œë¬¸/ìš´ìœ¨': 0,
        'ì„¤ëª…ë¬¸': 0,
        'ì¸ìš©ë¬¸': 0,
        'ì „ë¬¸ìš©ì–´': 0,
        'ì˜ë¬¸ë¬¸': 0,
        'ë³µí•©ë¬¸': 0
    }
    
    for row in test_data:
        src = str(row['ì›ë¬¸'])
        tgt = str(row['ë²ˆì—­ë¬¸'])
        
        # í•œì+ì¡°ì‚¬ í˜¼í•© (í•œì ë’¤ì— í•œê¸€ ì¡°ì‚¬)
        import re
        if re.search(r'[\u4e00-\u9fff][\uac00-\ud7af]{1,2}(?=\s|[\u4e00-\u9fff]|$)', src):
            features['í•œì+ì¡°ì‚¬ í˜¼í•©'] += 1
        
        # ì‹œë¬¸/ìš´ìœ¨ (íŠ¹ì • ì–´ë¯¸ë‚˜ ê°íƒ„ì‚¬)
        if re.search(r'[ì´]?ë¡œë‹¤|[ì´]?ëŸ¬ë‹ˆ|å“‰|ä¹Ÿ', src):
            features['ì‹œë¬¸/ìš´ìœ¨'] += 1
        
        # ì„¤ëª…ë¬¸ (ç®‹äº‘, æ­£ç¾©æ›° ë“±)
        if re.search(r'ç®‹äº‘|æ­£ç¾©æ›°|é‡‹.*æ–‡', src):
            features['ì„¤ëª…ë¬¸'] += 1
        
        # ì¸ìš©ë¬¸ (ë”°ì˜´í‘œë‚˜ ì¸ìš© í‘œì‹œ)
        if '"' in src or '"' in tgt or 'æ›°' in src:
            features['ì¸ìš©ë¬¸'] += 1
        
        # ì „ë¬¸ìš©ì–´ (é‡‹è‰, çˆ¾é›… ë“±)
        if re.search(r'é‡‹è‰|çˆ¾é›…|éƒ­ç’', src + tgt):
            features['ì „ë¬¸ìš©ì–´'] += 1
        
        # ì˜ë¬¸ë¬¸
        if re.search(r'ä¹[.?]?$|ê°€\?|ì€ê°€', tgt):
            features['ì˜ë¬¸ë¬¸'] += 1
        
        # ë³µí•©ë¬¸ (ì ‘ì†ì‚¬ë‚˜ ë³µë¬¸ êµ¬ì¡°)
        if re.search(r'ç„¶å¾Œ|å‰‡|è‹¥.*å‰‡|è€Œ|ä¸”', src) or len(src) > 50:
            features['ë³µí•©ë¬¸'] += 1
    
    return features

def validate_test_data():
    """ìƒì„±ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²€ì¦"""
    try:
        output_path = Path("real_test_data.xlsx")
        if not output_path.exists():
            logger.error(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {output_path}")
            return False
        
        df = pd.read_excel(output_path)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['id', 'ì›ë¬¸', 'ë²ˆì—­ë¬¸']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
            return False
        
        # ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
        empty_src = df[df['ì›ë¬¸'].isna() | (df['ì›ë¬¸'].str.strip() == '')].index.tolist()
        empty_tgt = df[df['ë²ˆì—­ë¬¸'].isna() | (df['ë²ˆì—­ë¬¸'].str.strip() == '')].index.tolist()
        
        if empty_src:
            logger.error(f"ë¹ˆ ì›ë¬¸ì´ ìˆëŠ” í–‰: {empty_src}")
            return False
        
        if empty_tgt:
            logger.error(f"ë¹ˆ ë²ˆì—­ë¬¸ì´ ìˆëŠ” í–‰: {empty_tgt}")
            return False
        
        logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²€ì¦ ì™„ë£Œ: {len(df)}ê°œ í–‰, ëª¨ë“  ê²€ì‚¬ í†µê³¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

if __name__ == "__main__":
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        output_path = create_real_test_data()
        
        # ê²€ì¦ ìˆ˜í–‰
        if validate_test_data():
            logger.info(f"ğŸ‰ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ë° ê²€ì¦ ì™„ë£Œ!")
            logger.info(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {output_path.absolute()}")
        else:
            logger.error("âŒ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨")
    
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")