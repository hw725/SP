"""íŒŒì¼ ì²˜ë¦¬ ë©”ì¸ í”„ë¡œì„¸ì„œ"""

import io_utils  # ìƒëŒ€ ì„í¬íŠ¸ â†’ ì ˆëŒ€ ì„í¬íŠ¸ë¡œ ë³€ê²½
from tokenizer import split_src_meaning_units, split_tgt_meaning_units
from aligner import align_tokens_with_embeddings
from embedder import get_embeddings
import pandas as pd
import logging
from typing import Optional

logger = logging.getLogger(__name__)

def process_file(
    input_file: str,
    output_file: str,
    use_semantic: bool = True,
    min_tokens: int = 2,
    max_tokens: int = 10
) -> bool:
    """
    íŒŒì¼ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    Args:
        input_file: ì…ë ¥ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        output_file: ì¶œë ¥ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        use_semantic: ì˜ë¯¸ ê¸°ë°˜ ë¶„í•  ì‚¬ìš© ì—¬ë¶€
        min_tokens: ìµœì†Œ í† í° ìˆ˜
        max_tokens: ìµœëŒ€ í† í° ìˆ˜
    
    Returns:
        bool: ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
    """
    try:
        logger.info(f"ğŸ“ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {input_file}")
        
        # 1. íŒŒì¼ ë¡œë“œ
        df = io_utils.load_excel_file(input_file)
        if df is None:
            logger.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {input_file}")
            return False
        
        logger.info(f"ğŸ“Š ì²˜ë¦¬í•  ë¬¸ì¥ ìˆ˜: {len(df)}")
        
        results = []
        
        # 2. ê° ë¬¸ì¥ ì²˜ë¦¬
        for idx, row in df.iterrows():
            try:
                src_text = str(row['src']).strip()
                tgt_text = str(row['tgt']).strip()
                
                if not src_text or not tgt_text:
                    logger.warning(f"âš ï¸ í–‰ {idx}: ë¹ˆ í…ìŠ¤íŠ¸ ë°œê²¬")
                    continue
                
                logger.info(f"ğŸ”¤ ë¬¸ì¥ {idx+1} ì²˜ë¦¬ ì¤‘...")
                
                # ì›ë¬¸ ë¶„í• 
                src_units = split_src_meaning_units(
                    src_text,
                    min_tokens=min_tokens,
                    max_tokens=max_tokens
                )
                
                # ë²ˆì—­ë¬¸ ë¶„í• 
                if use_semantic:
                    # ì‹¤ì œ ì„ë² ë”© ì‚¬ìš©
                    tgt_units = split_tgt_meaning_units(
                        src_text, tgt_text,
                        embed_func=get_embeddings,
                        use_semantic=True,
                        min_tokens=min_tokens,
                        max_tokens=max_tokens
                    )
                else:
                    # ë‹¨ìˆœ ë¶„í• 
                    tgt_units = split_tgt_meaning_units(
                        src_text, tgt_text,
                        embed_func=None,
                        use_semantic=False,
                        min_tokens=min_tokens,
                        max_tokens=max_tokens
                    )
                
                # ì •ë ¬ ìˆ˜í–‰
                if use_semantic:
                    alignments = align_tokens_with_embeddings(
                        src_units, tgt_units,
                        src_text, tgt_text
                    )
                else:
                    # ë‹¨ìˆœ ì •ë ¬ (ìˆœì„œëŒ€ë¡œ)
                    alignments = []
                    min_len = min(len(src_units), len(tgt_units))
                    for i in range(min_len):
                        alignments.append({
                            'src_idx': i,
                            'tgt_idx': i,
                            'src_text': src_units[i],
                            'tgt_text': tgt_units[i],
                            'confidence': 0.5  # ê¸°ë³¸ê°’
                        })
                
                # ê²°ê³¼ ì €ì¥
                result = {
                    'id': row.get('id', idx),
                    'src': src_text,
                    'tgt': tgt_text,
                    'src_units': str(src_units),
                    'tgt_units': str(tgt_units),
                    'alignments': str(alignments),
                    'src_count': len(src_units),
                    'tgt_count': len(tgt_units),
                    'alignment_count': len(alignments)
                }
                
                results.append(result)
                logger.info(f"âœ… ë¬¸ì¥ {idx+1} ì²˜ë¦¬ ì™„ë£Œ: {len(src_units)}â†’{len(tgt_units)} ({len(alignments)}ì •ë ¬)")
                
            except Exception as e:
                logger.error(f"âŒ ë¬¸ì¥ {idx+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ê²½ìš°ë¼ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì €ì¥
                results.append({
                    'id': row.get('id', idx),
                    'src': str(row.get('src', '')),
                    'tgt': str(row.get('tgt', '')),
                    'src_units': '[]',
                    'tgt_units': '[]',
                    'alignments': '[]',
                    'src_count': 0,
                    'tgt_count': 0,
                    'alignment_count': 0,
                    'error': str(e)
                })
        
        # 3. ê²°ê³¼ ì €ì¥
        if results:
            success = io_utils.save_alignment_results(results, output_file)
            if success:
                logger.info(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
                logger.info(f"ğŸ“Š ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ë¬¸ì¥")
                return True
            else:
                logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {output_file}")
                return False
        else:
            logger.error("âŒ ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
            
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False

def process_single_sentence(
    src_text: str,
    tgt_text: str,
    use_semantic: bool = True,
    min_tokens: int = 2,
    max_tokens: int = 10
) -> Optional[dict]:
    """
    ë‹¨ì¼ ë¬¸ì¥ ì²˜ë¦¬
    
    Args:
        src_text: ì›ë¬¸
        tgt_text: ë²ˆì—­ë¬¸
        use_semantic: ì˜ë¯¸ ê¸°ë°˜ ë¶„í•  ì‚¬ìš© ì—¬ë¶€
        min_tokens: ìµœì†Œ í† í° ìˆ˜
        max_tokens: ìµœëŒ€ í† í° ìˆ˜
    
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ ë˜ëŠ” None
    """
    try:
        logger.info(f"ğŸ”¤ ë‹¨ì¼ ë¬¸ì¥ ì²˜ë¦¬: {src_text[:50]}...")
        
        # ì›ë¬¸ ë¶„í• 
        src_units = split_src_meaning_units(
            src_text,
            min_tokens=min_tokens,
            max_tokens=max_tokens
        )
        
        # ë²ˆì—­ë¬¸ ë¶„í• 
        if use_semantic:
            tgt_units = split_tgt_meaning_units(
                src_text, tgt_text,
                embed_func=get_embeddings,
                use_semantic=True,
                min_tokens=min_tokens,
                max_tokens=max_tokens
            )
            
            # ì •ë ¬
            alignments = align_tokens_with_embeddings(
                src_units, tgt_units,
                src_text, tgt_text
            )
        else:
            tgt_units = split_tgt_meaning_units(
                src_text, tgt_text,
                embed_func=None,
                use_semantic=False,
                min_tokens=min_tokens,
                max_tokens=max_tokens
            )
            
            # ë‹¨ìˆœ ì •ë ¬
            alignments = []
            min_len = min(len(src_units), len(tgt_units))
            for i in range(min_len):
                alignments.append({
                    'src_idx': i,
                    'tgt_idx': i,
                    'src_text': src_units[i],
                    'tgt_text': tgt_units[i],
                    'confidence': 0.5
                })
        
        result = {
            'src': src_text,
            'tgt': tgt_text,
            'src_units': src_units,
            'tgt_units': tgt_units,
            'alignments': alignments,
            'src_count': len(src_units),
            'tgt_count': len(tgt_units),
            'alignment_count': len(alignments)
        }
        
        logger.info(f"âœ… ë‹¨ì¼ ë¬¸ì¥ ì²˜ë¦¬ ì™„ë£Œ: {len(src_units)}â†’{len(tgt_units)}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ ë‹¨ì¼ ë¬¸ì¥ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    logging.basicConfig(level=logging.INFO)
    
    test_src = "èˆˆä¹Ÿë¼"
    test_tgt = "èˆˆì´ë‹¤."
    
    result = process_single_sentence(test_src, test_tgt, use_semantic=False)
    if result:
        print("âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        print(f"ì›ë¬¸ ë¶„í• : {result['src_units']}")
        print(f"ë²ˆì—­ ë¶„í• : {result['tgt_units']}")
        print(f"ì •ë ¬ ê²°ê³¼: {result['alignments']}")
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
