"""í† í° ì •ë ¬ ëª¨ë“ˆ - regex ì§€ì›"""

import numpy as np
import re
import regex  # ğŸ†• ìœ ë‹ˆì½”ë“œ ì†ì„± ì •ê·œì‹
from typing import List, Dict, Tuple, Optional
import logging
from sa_embedders import compute_embeddings_with_cache  # ğŸ”§ ìˆ˜ì •

logger = logging.getLogger(__name__)

def align_tokens_with_embeddings(
    src_units: List[str],
    tgt_units: List[str],
    src_text: str = "",
    tgt_text: str = "",
    threshold: float = 0.3
) -> List[Dict]:
    """ì„ë² ë”© ê¸°ë°˜ í† í° ì •ë ¬"""
    
    try:
        if not src_units or not tgt_units:
            logger.warning("âš ï¸ ë¹ˆ í† í° ë¦¬ìŠ¤íŠ¸")
            return []
        
        logger.info(f"ğŸ”— í† í° ì •ë ¬ ì‹œì‘: {len(src_units)} â†’ {len(tgt_units)}")
        
        # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        similarity_matrix = batch_similarity(src_units, tgt_units)
        
        if similarity_matrix.size == 0:
            logger.error("âŒ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚° ì‹¤íŒ¨")
            return _fallback_alignment(src_units, tgt_units)
        
        alignments = []
        
        # ì •ë ¬ ë¡œì§ + í•œì ë§¤ì¹­ ê°€ì¤‘ì¹˜
        if len(src_units) == 1 and len(tgt_units) > 1:
            # 1:N ì •ë ¬
            tgt_combined = ' '.join(tgt_units)
            confidence = _calculate_enhanced_confidence(
                src_units[0], tgt_combined, similarity_matrix
            )
            
            alignments.append({
                'src_idx': 0,
                'tgt_idx': list(range(len(tgt_units))),
                'src_text': src_units[0],
                'tgt_text': tgt_combined,
                'confidence': float(confidence),
                'alignment_type': f'1:{len(tgt_units)}'
            })
            
        elif len(src_units) > 1 and len(tgt_units) == 1:
            # N:1 ì •ë ¬
            src_combined = ' '.join(src_units)
            confidence = _calculate_enhanced_confidence(
                src_combined, tgt_units[0], similarity_matrix
            )
            
            alignments.append({
                'src_idx': list(range(len(src_units))),
                'tgt_idx': 0,
                'src_text': src_combined,
                'tgt_text': tgt_units[0],
                'confidence': float(confidence),
                'alignment_type': f'{len(src_units)}:1'
            })
            
        else:
            # 1:1 ì •ë ¬ with í•œì ë§¤ì¹­ ë³´ë„ˆìŠ¤
            min_len = min(len(src_units), len(tgt_units))
            
            for i in range(min_len):
                base_confidence = similarity_matrix[i, i] if (i < similarity_matrix.shape[0] and i < similarity_matrix.shape[1]) else 0.3
                
                # ğŸ†• í•œì ë§¤ì¹­ ë³´ë„ˆìŠ¤
                han_bonus = _calculate_han_matching_bonus(src_units[i], tgt_units[i])
                final_confidence = min(1.0, base_confidence + han_bonus)
                
                alignments.append({
                    'src_idx': i,
                    'tgt_idx': i,
                    'src_text': src_units[i],
                    'tgt_text': tgt_units[i],
                    'confidence': float(final_confidence),
                    'alignment_type': '1:1'
                })
        
        logger.info(f"âœ… ì •ë ¬ ì™„ë£Œ: {len(alignments)}ê°œ ìŒ")
        return alignments
        
    except Exception as e:
        logger.error(f"âŒ í† í° ì •ë ¬ ì‹¤íŒ¨: {e}")
        return _fallback_alignment(src_units, tgt_units)

def _calculate_enhanced_confidence(src_text: str, tgt_text: str, similarity_matrix: np.ndarray) -> float:
    """ê°•í™”ëœ ì‹ ë¢°ë„ ê³„ì‚°"""
    
    base_confidence = np.max(similarity_matrix) if similarity_matrix.size > 0 else 0.3
    
    # í•œì ë§¤ì¹­ ë³´ë„ˆìŠ¤
    han_bonus = _calculate_han_matching_bonus(src_text, tgt_text)
    
    # ê¸¸ì´ ë¹„ìœ¨ ë³´ë„ˆìŠ¤
    len_ratio = min(len(src_text), len(tgt_text)) / max(len(src_text), len(tgt_text)) if max(len(src_text), len(tgt_text)) > 0 else 0
    length_bonus = len_ratio * 0.1
    
    return min(1.0, base_confidence + han_bonus + length_bonus)

def _calculate_han_matching_bonus(src_text: str, tgt_text: str) -> float:
    """ğŸ†• í•œì ë§¤ì¹­ ë³´ë„ˆìŠ¤ ê³„ì‚°"""
    
    try:
        # ì›ë¬¸ì—ì„œ í•œì ì¶”ì¶œ
        src_han = set(regex.findall(r'\p{Han}', src_text))
        # ë²ˆì—­ë¬¸ì—ì„œ í•œì ì¶”ì¶œ 
        tgt_han = set(regex.findall(r'\p{Han}', tgt_text))
        
        if not src_han:
            return 0.0
        
        # í•œì ì¼ì¹˜ìœ¨ ê³„ì‚°
        common_han = src_han & tgt_han
        if common_han:
            match_ratio = len(common_han) / len(src_han)
            return match_ratio * 0.3  # ìµœëŒ€ 0.3 ë³´ë„ˆìŠ¤
        
        return 0.0
        
    except Exception as e:
        logger.debug(f"í•œì ë§¤ì¹­ ë³´ë„ˆìŠ¤ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0

def _fallback_alignment(src_units: List[str], tgt_units: List[str]) -> List[Dict]:
    """ë°±ì—… ì •ë ¬"""
    
    alignments = []
    min_len = min(len(src_units), len(tgt_units))
    
    for i in range(min_len):
        # ğŸ†• ë°±ì—…ì—ì„œë„ í•œì ë§¤ì¹­ ì‹œë„
        han_bonus = _calculate_han_matching_bonus(src_units[i], tgt_units[i])
        confidence = 0.3 + han_bonus
        
        alignments.append({
            'src_idx': i,
            'tgt_idx': i,
            'src_text': src_units[i],
            'tgt_text': tgt_units[i],
            'confidence': float(confidence),
            'alignment_type': '1:1-fallback'
        })
    
    return alignments

# í•¨ìˆ˜ëª…ì„ processor.pyì—ì„œ í˜¸ì¶œí•˜ëŠ” ì´ë¦„ê³¼ ë§ì¶¤
def align_tokens(src_units, tgt_units, embed_func=None):
    """processor.py í˜¸í™˜ìš© wrapper"""
    return align_tokens_with_embeddings(src_units, tgt_units, embed_func=embed_func)